# Why AI coding tools accidentally feel perfect for inattentive ADHD brains
**Score:** 154 | **Comments:** 61 | **Subreddit:** r/ClaudeCode
**URL:** https://www.reddit.com/r/ClaudeCode/comments/1qeb6od/why_ai_coding_tools_accidentally_feel_perfect_for/
**Author:** u/bystanderInnen

## Post Content

A funny side effect of AI-assisted coding is that it seems to fit inattentive ADHD brains unusually well.

These brains are often bad at linear recall and memorization, but very good at pattern recognition, big-picture thinking, and creative problem solving. They also rely heavily on external context because internal state tends to get dropped. Forgetting isn't a bug, it's the default mode.

Which is basically how LLMs work.

AI tools like Claude Code don't "remember" things either. They need exact context every time. They think in patterns, not facts. They generate plausible structure and then need verification. In other words, they operate in a way inattentive ADHD brains have been compensating for their entire lives.

The real win isn't that they write code. It's that they externalize working memory and collapse activation cost. Reading a codebase, summarizing architecture, drafting tests, proposing refactors, updating docs all become cheap first passes instead of momentum killers.

Hallucinations aren't surprising here. They're familiar. You handle them the same way: verify, test, correct, repeat. Treat the output as untrusted and it works fine.

So it's kind of ironic. A lot of people struggle with AI because it "forgets things" or "needs constant context." Meanwhile, some neurodivergent brains are like: yes, welcome to how this has always worked.

Not AI replacing engineers. Just a tool that finally speaks fluent pattern-thinking.

---

## Top Comments

### u/texo_optimo (Score: 33)
That's how I adapted when my repos grew. Mega ADHD here and started to recognize the context limitations as I was learning more. I started with an ADHD prompting system, that evolved into CC agents utilizing the same framework. Then I started looking at it beyond prompting and as a method for managing context. Now I'm using my own governance remote mcp server / project board that serves as record of decisions and "memory" of sorts for architectural decisions across every project.

I began to realize how I could "parking lot" ideas more easily if I managed my own context the same way. This let's me ideate and iterate on so many things that would have gone into the ether. It may sound corny, but utilizing LMs heavily have helped me see my constraint as a feature.

### u/nnennahacks (Score: 20)
Completely agree. For me, AI lets me think the way my brain already thinks without paying the burnout tax. My brain runs at like a thousand tabs open all the time. Deep dives, tangents, pattern jumps, sudden connections. Normally, context switching kills momentum and drains me fast. With AI, I can bounce between ideas, explore them deeply, and externalize the chaos instead of trying to hold it all in my head. It feels like I finally have somewhere to put the thoughts. AI matches my operating system. For coding, brainstorming, strategizing, planning, learning, building.

### u/IulianHI (Score: 10)
Good point here :)

### u/drumnation (Score: 10)
It's been life changing. All of a sudden the way my brain naturally works feels like the biggest cheat code working with ai. I can talk at it for 10 minutes and have the richest context possible and come back with the work done. It's like specifically the parts that were harder for my brain are now effortless because ai handles them and that greases the wheels for the specifically ADHD traits to be utilized as positive traits moving the work along.

And it's really not hard to notice that wild tangential thinking actually producing insane results when you can run multiple agents in parallel. Honestly that tangential thinking + AI has become my greatest feature instead of a bug.

AI has become a sort of ADHD prosthetic that I think in time will completely remove the bottlenecks ADHD presents for many of us and instead enable full neuro divergent capacity.

### u/daSoulLaSlick (Score: 8)
You just shattered 1000s of posts complaining that AI forgot my context on Reddit.

### u/FlaTreNeb (Score: 7)
Absolutely feel that. It's like transformer models are mimicking ADHD mental models. That's why properly handling the prompting and context engineering felt ... native.

### u/pborenstein (Score: 5)
Lol. that explains why the side project to my side project is a system for wrapping up after every session.

### u/jmdejoanelli (Score: 4)
Now, add autism to the mix: requiring unambiguous communication, explicit outlining of rules and directives, benefiting from examples of success and failure etc. all things that are really helpful for promoting LLMs. My neurotypical colleagues seem to struggle with understanding the subtle properties of effective prompts and context handling, whereas I've always had an intuitive knack for it. I literally think it's because my AuDHD brain has the same promoting requirements as an LLM so I just talk to it like I wish people would talk to me lol

### u/Datamance (Score: 4)
THIS. This is what we're good at. Context dumping! Surfacing constraints! Abstracting! Identifying normative principles! What does the word-machine want? All that.

### u/UhhYeahMightBeWrong (Score: 3)
Yes, absolutely agree with what you are pointing out here. As someone with ADHD I am often struck by just how much techniques that I use with Claude Code, e.g. managing context and keeping scope narrow, can be helpful for my own cognition.

### u/drumnation (Score: 3)
I went the opposite direction. Built the system for agents and realized wait a minute this is how other people should communicate with me. And how I need to be tracking my own work.

### u/El_Spanberger (Score: 2)
AuDHD here. Saw a UK Gov study on 20,000 civil servants using M365 Copilot. ND folks were singled out as exceptional performers - obviously something about LLMs in general is like nectar to us.
